[{"index":1,"title":"阿西莫夫机器人三定律(GIGI是否违反这里的规定？) (转)","content":"阿西莫夫机器人三定律(GIGI是否违反这里的规定？)&nbsp;&nbsp;\r<br>&nbsp;第一定律:机器人不得伤害人,也不得见人受到伤害而袖手旁观。&nbsp;&nbsp;\r<br>第二定律:机器人应服从人的一切命令,但不得违反第一定律。&nbsp;&nbsp;\r<br>第三定律:机器人应保护自身的安全,但不得违反第一、第二定律。&nbsp;&nbsp;\r<br>\r<br>据说后来有人（或者他自己）补充了0定律、-1定律还是什么的&nbsp;\r<br>\r<br>机器人必须保护人类的整体利益不受伤害，其它三条定律都是在这一前提下才能成立。&nbsp;&nbsp;\r<br>为什么后来要定出这条“零定律”呢？打个比方，为了维持国家或者说世界的整体秩序，我们制定法律，必须要执行一些人的死刑。这种情况下，机器人该不该阻止死刑的执行呢？显然是不允许的，因为这样就破坏了我们维持的秩序，也就是伤害了人类的整体利益。&nbsp;&nbsp;\r<br>\r<br>所以新的阿西莫夫的定律为：&nbsp;&nbsp;\r<br>第零定律：机器人不得伤害人类，或目睹人类将遭受危险而袖手不管。&nbsp;&nbsp;\r<br>第一定律：机器人不得伤害人类个体，或者目睹人类个体将遭受危险而袖手不管，除非这违反了机器人学第零定律。&nbsp;&nbsp;\r<br>第二定律：机器人必须服从人给予它的命令，当该命令与第零定律或者第一定律冲突时例外。&nbsp;&nbsp;\r<br>第三：机器人在不违反第零、第一、第二定律的情况下要尽可能保护自己的生存。&nbsp;&nbsp;\r<br>\r<br>三定律加上零定律，看来堪称完美，但是，“人类的整体利益”这种混沌的概念，连人类自己都搞不明白，更不要说那些用0和1来想问题的机器人了。威尔&#8226;史密斯曾说：“《我，机器人》的中心概念是机器人没有问题，科技本身也不是问题，人类逻辑的极限才是真正的问题。”的确，人类现有的逻辑对很多问题都是无能为力的，所以，个人认为所谓的“零定律”根本是起不到什么作用的。&nbsp;&nbsp;\r<br>\r<br>\r<br>除此，另一个科幻作家罗杰·克拉克在一篇论文中还指出了三条潜在的定律：&nbsp;&nbsp;\r<br>元定律：机器人可以什么也不做，除非它的行动符合机器人学定律。此定律置于第零、第一、第二、第三定律之前。&nbsp;&nbsp;\r<br>第四定律：机器人必须履行内置程序所赋予的责任，除非这与其他高阶的定律冲突。&nbsp;&nbsp;\r<br>繁殖定律：机器人不得参与机器人的设计和制造，除非新的机器人的行动服从机器人学定律。&nbsp;&nbsp;\r<br>&nbsp;\r<br>\u0018","author":"刘飒ASAFE","author_link":"https://tieba.baidu.com/home/main?id=tb.1.bbc36295.cyspoZQMuIC0zms4XekEqQ&fr=pb","date":"2006-11-16 13:19","ip":null,"old_image":null,"user_sign_image":null},{"index":2,"title":"回复：阿西莫夫机器人三定律(GIGI是否违反这里的规定？) (转)","content":"这是漫画，应该无所畏吧�","author":"221.2.6.*","author_link":null,"date":"2006-11-16 18:34","ip":null,"old_image":null,"user_sign_image":null},{"index":3,"title":"回复：阿西莫夫机器人三定律(GIGI是否违反这里的规定？) (转)","content":"a","author":"220.170.14.*","author_link":null,"date":"2006-12-11 18:41","ip":null,"old_image":null,"user_sign_image":null}]